{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import dns.resolver\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "PHISH_DIR = DATA_DIR / 'phishtank'\n",
    "LEGIT_DIR = DATA_DIR / 'common_crawl'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "PHISH_DATA = PHISH_DIR / 'collected_data.csv'\n",
    "LEGIT_DATA = LEGIT_DIR / 'collected_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish = pd.read_csv(PHISH_DATA)\n",
    "df_valid = pd.read_csv(LEGIT_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = pd.read_csv(PROCESSED_DIR / 'phish_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reapplying Rules\n",
    "Some address based indicators were updated after they were collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urljoin\n",
    "import whois\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whois(url):\n",
    "    \"\"\"Gets the WHOIS information of a URL.\"\"\"\n",
    "    try:\n",
    "        whois_data = whois.whois(url.lower())\n",
    "        return whois_data\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# CloudFlare\n",
    "top_phishing_tlds = [\n",
    "    # Cheap and Open TLDs\n",
    "    \".xyz\", \".top\", \".club\", \".online\", \".shop\", \".site\", \".vip\", \".buzz\",\n",
    "\n",
    "    # Freenom TLDs (Free Domains)\n",
    "    \".tk\", \".ml\", \".ga\", \".cf\", \".gq\",\n",
    "\n",
    "    # Geographic and Niche TLDs less commonly used for legitimate purposes\n",
    "    \".ly\", \".to\", \".ru\", \".cn\", \".su\"\n",
    "]\n",
    "\n",
    "def is_statistical_report(url):\n",
    "    \"\"\"Determines if the URL has a suspicious statistical report based on phishing domains or IPs.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    if f\".{ext.suffix}\" in top_phishing_tlds:\n",
    "        return -1  # Phishing\n",
    "    \n",
    "    return 1 \n",
    "\n",
    "def core_domain(url):\n",
    "    \"\"\"Normalize the URL by extracting only the core domain using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    core_domain = f\"{extracted.domain}.{extracted.suffix}\"\n",
    "    return core_domain\n",
    "\n",
    "def domain_name(url):\n",
    "    \"\"\"Normalize the URL by extracting only the domain name using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    return extracted.domain\n",
    "\n",
    "url_shortening_services = [\n",
    "    # Legitimate Shortening Services\n",
    "    \"bit.ly\", \"tinyurl.com\", \"t.co\", \"is.gd\", \"ow.ly\",\n",
    "    \"buff.ly\", \"rebrand.ly\", \"sh.st\", \"adf.ly\", \"bl.ink\",\n",
    "    \"clck.ru\", \"mcaf.ee\", \"tiny.cc\", \"fb.me\", \"amzn.to\",\n",
    "    \"lnkd.in\", \"yt.be\", \"wp.me\", \"git.io\", \"nyti.ms\",\n",
    "    \"es.pn\", \"cnn.it\",\n",
    "\n",
    "    # Known Suspicious or Exploited Shorteners\n",
    "    \"goo.gl\", \"cut.ly\", \"rb.gy\", \"soo.gd\", \"t.ly\",\n",
    "    \"v.gd\", \"qr.ae\", \"x.co\", \"zl.gg\", \"tr.im\",\n",
    "    \"linktr.ee\", \"phurl.me\", \"short.cm\", \"cutt.ly\"\n",
    "]\n",
    "def is_shortening_service(url):\n",
    "    \"\"\"Determines if the URL uses a URL shortening service.\"\"\"\n",
    "    core = core_domain(url)\n",
    "    if core in url_shortening_services:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "def is_url_long(url):\n",
    "    \"\"\"Determines if the URL length is suspicious or phishing based on length.\"\"\"\n",
    "    url_length = len(url)\n",
    "    \n",
    "    if url_length < 54:\n",
    "        return 1  # Legitimate\n",
    "    elif 54 <= url_length <= 75:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1  # Phishing\n",
    "\n",
    "def is_double(url):\n",
    "    \"\"\"Determines if the URL redirects using '//'.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.scheme == \"http\":\n",
    "        limit_position = 6\n",
    "    elif parsed_url.scheme == \"https\":\n",
    "        limit_position = 7\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    last_occurrence_index = url.rfind(\"//\")\n",
    "\n",
    "    if last_occurrence_index > limit_position:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def is_dns_record(url, timeout=5):\n",
    "    \"\"\"Check if the domain or subdomain has DNS records.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "    \n",
    "    resolver = dns.resolver.Resolver()\n",
    "    resolver.timeout = timeout\n",
    "    resolver.lifetime = timeout  # Set a timeout for the entire resolution process\n",
    "    \n",
    "    try:\n",
    "        a_records = resolver.resolve(domain, 'A')\n",
    "        if a_records:\n",
    "            return 1\n",
    "    except dns.resolver.NoAnswer:\n",
    "        pass\n",
    "    except dns.resolver.NXDOMAIN:\n",
    "        return -1\n",
    "    except dns.exception.Timeout:\n",
    "        return -1\n",
    "    except dns.resolver.NoNameservers:\n",
    "        return -1\n",
    "    \n",
    "    try:\n",
    "        aaaa_records = resolver.resolve(domain, 'AAAA')\n",
    "        if aaaa_records:\n",
    "            return 1\n",
    "    except dns.resolver.NoAnswer:\n",
    "        pass\n",
    "    except dns.resolver.NXDOMAIN:\n",
    "        return -1\n",
    "    except dns.exception.Timeout:\n",
    "        return -1\n",
    "    except dns.resolver.NoNameservers:\n",
    "        return -1\n",
    "    \n",
    "    return -1\n",
    "    \n",
    "def is_having_sub_domain(url):\n",
    "    \"\"\"Classifies a URL based on the number of subdomains.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    subdomain = ext.subdomain\n",
    "    num_subdomains = len(subdomain.split('.')) if subdomain else 0\n",
    "    \n",
    "    if num_subdomains == 0:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 1:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 2:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def is_abnormal_url(url):\n",
    "    \"\"\"Determines if the URL is abnormal.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    host_name = ext.domain + '.' + ext.suffix\n",
    "    w = whois.whois(url)\n",
    "    if w and 'domain_name' in w:\n",
    "        domain_names = w['domain_name']\n",
    "        print(f\"Domain names: {domain_names}\")\n",
    "        if isinstance(domain_names, list):\n",
    "            for domain in domain_names:\n",
    "                if host_name.lower() == domain.lower():\n",
    "                    return 1\n",
    "        elif isinstance(domain_names, str):\n",
    "            if host_name.lower() == domain_names.lower():\n",
    "                return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url_online(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        # Check if the status code indicates success (2xx range)\n",
    "        if response.status_code >= 200 and response.status_code < 300:\n",
    "            return True  # URL is online\n",
    "        else:\n",
    "            print (f\"URL is not online, or is responding with an error code: {response.status_code}\")\n",
    "            return False  # URL is not online, or is responding with an error code\n",
    "    except requests.RequestException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # This enables tqdm for pandas' apply method\n",
    "\n",
    "# Apply the function with progress tracking\n",
    "df_phish = df_phish[df_phish['website_url'].progress_apply(is_url_online)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of phishing URLs after filtering: {len(df_phish)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish.drop_duplicates(subset=['website_url'], inplace=True)\n",
    "df_valid.drop_duplicates(subset=['website_url'], inplace=True)\n",
    "\n",
    "df_phish['statistical_report'] = df_phish['website_url'].apply(is_statistical_report)\n",
    "df_valid['statistical_report'] = df_valid['website_url'].apply(is_statistical_report)\n",
    "df_phish['shortining_service'] = df_phish['website_url'].apply(is_shortening_service)\n",
    "df_valid['shortining_service'] = df_valid['website_url'].apply(is_shortening_service)\n",
    "df_phish['url_length'] = df_phish['website_url'].apply(is_url_long)\n",
    "df_valid['url_length'] = df_valid['website_url'].apply(is_url_long)\n",
    "df_phish['having_sub_domain'] = df_phish['website_url'].apply(is_having_sub_domain)\n",
    "df_valid['having_sub_domain'] = df_valid['website_url'].apply(is_having_sub_domain)\n",
    "df_phish['double_slash_redirecting'] = df_phish['website_url'].apply(is_double)\n",
    "df_valid['double_slash_redirecting'] = df_valid['website_url'].apply(is_double)\n",
    "df_phish['dnsrecord'] = df_phish['website_url'].progress_apply(is_dns_record)\n",
    "df_valid['dnsrecord'] = df_valid['website_url'].progress_apply(is_dns_record)\n",
    "df_phish['abnormal_url'] = df_phish['website_url'].progress_apply(is_abnormal_url)\n",
    "df_valid['abnormal_url'] = df_valid['website_url'].progress_apply(is_abnormal_url)\n",
    "df_phish['result'] = -1\n",
    "df_valid['result'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish.to_csv(PROCESSED_DIR / 'phish_data.csv', index=False)\n",
    "df_valid.to_csv(PROCESSED_DIR / 'valid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def create_table(data, headers):\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(df):\n",
    "    metrics = []\n",
    "    data = []\n",
    "    for col in df.columns:\n",
    "        if col == 'result':\n",
    "            continue\n",
    "        \n",
    "        value_counts = df[col].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "        phishing = value_counts.get(-1, 0)\n",
    "        suspicious = value_counts.get(0, 0)\n",
    "        legitimate = value_counts.get(1, 0)\n",
    "        \n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df['result'] = pd.to_numeric(df['result'], errors='coerce')\n",
    "        \n",
    "        TP = ((df[col] == -1) & (df['result'] == -1)).sum()\n",
    "        FP = (((df[col] == -1) | (df[col] == 0)) & (df['result'] == 1)).sum()\n",
    "        TN = ((df[col] == 1) & (df['result'] == 1)).sum()\n",
    "        FN = (((df[col] == 1) | (df[col] == 0)) & (df['result'] == -1)).sum()\n",
    "        \n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "        metrics.append({\n",
    "            'Feature': col,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "        data.append([col, phishing, suspicious, legitimate, precision, recall, accuracy])\n",
    "\n",
    "\n",
    "    headers = [\"Feature\",\"Phishing (-1)\", \"Suspicious (0)\",\"Legitimate (1)\", \"Precision (%)\", \"Recall (%)\", \"Accuracy (%)\"]\n",
    "    create_table(data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(df_phish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════════════════════╤═════════════════╤══════════════════╤══════════════════╤═════════════════╤══════════════╤════════════════╕\n",
      "│ Feature                    │   Phishing (-1) │   Suspicious (0) │   Legitimate (1) │   Precision (%) │   Recall (%) │   Accuracy (%) │\n",
      "╞════════════════════════════╪═════════════════╪══════════════════╪══════════════════╪═════════════════╪══════════════╪════════════════╡\n",
      "│ website_url                │               0 │                0 │                0 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ having_ip_address          │               0 │                0 │             2338 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ url_length                 │             190 │              184 │             1964 │               1 │   0.081266   │     0.081266   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ shortining_service         │             101 │                0 │             2237 │               1 │   0.0431993  │     0.0431993  │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ having_at_symbol           │               8 │                0 │             2330 │               1 │   0.00342173 │     0.00342173 │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ double_slash_redirecting   │               7 │                0 │             2331 │               1 │   0.00299401 │     0.00299401 │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ prefix_suffix              │             812 │                0 │             1526 │               1 │   0.347305   │     0.347305   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ having_sub_domain          │               4 │               49 │             2285 │               1 │   0.00171086 │     0.00171086 │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ sslfinal_state             │              21 │             2317 │                0 │               1 │   0.00898204 │     0.00898204 │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ domain_registration_length │             397 │                0 │             1941 │               1 │   0.169803   │     0.169803   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ favicon                    │            1124 │                0 │             1214 │               1 │   0.480753   │     0.480753   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ port                       │               0 │                0 │             2338 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ https_token                │               0 │                0 │             2338 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ request_url                │             697 │              286 │             1355 │               1 │   0.298118   │     0.298118   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ url_of_anchor              │             229 │              545 │             1564 │               1 │   0.097947   │     0.097947   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ links_in_tags              │             391 │              649 │             1298 │               1 │   0.167237   │     0.167237   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ sfh                        │             186 │               35 │             2117 │               1 │   0.0795552  │     0.0795552  │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ submitting_to_email        │              78 │                0 │             2260 │               1 │   0.0333618  │     0.0333618  │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ abnormal_url               │             377 │                0 │             1961 │               1 │   0.161249   │     0.161249   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ redirect                   │              21 │               94 │             2223 │               1 │   0.00898204 │     0.00898204 │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ on_mouseover               │               0 │                0 │             2338 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ rightclick                 │              52 │                0 │             2286 │               1 │   0.0222412  │     0.0222412  │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ popupwindow                │               0 │                0 │             2338 │               0 │   0          │     0          │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ iframe                     │             324 │                0 │             2014 │               1 │   0.13858    │     0.13858    │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ age_of_domain              │             584 │                0 │             1754 │               1 │   0.249786   │     0.249786   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ dnsrecord                  │             113 │                0 │             2225 │               1 │   0.0483319  │     0.0483319  │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ web_traffic                │            2190 │               58 │               90 │               1 │   0.936698   │     0.936698   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ page_rank                  │            1400 │                0 │              938 │               1 │   0.598802   │     0.598802   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ google_index               │            1864 │                0 │              474 │               1 │   0.797263   │     0.797263   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ links_pointing_to_page     │            1126 │              909 │              303 │               1 │   0.481608   │     0.481608   │\n",
      "├────────────────────────────┼─────────────────┼──────────────────┼──────────────────┼─────────────────┼──────────────┼────────────────┤\n",
      "│ statistical_report         │             154 │                0 │             2184 │               1 │   0.0658683  │     0.0658683  │\n",
      "╘════════════════════════════╧═════════════════╧══════════════════╧══════════════════╧═════════════════╧══════════════╧════════════════╛\n"
     ]
    }
   ],
   "source": [
    "df_processed['result'] = -1\n",
    "statistics(df_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed['statistical_report'] =  df_processed['website_url'].apply(is_statistical_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_subdomain(url):\n",
    "    \"\"\"Check if the URL has a subdomain.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    subdomain = ext.subdomain\n",
    "    if subdomain:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of URLs with subdomains: 1888\n"
     ]
    }
   ],
   "source": [
    "df_processed['subdomain_count'] = df_processed['website_url'].apply(check_for_subdomain)\n",
    "true_count = df_processed['subdomain_count'].sum()\n",
    "print(f\"Number of URLs with subdomains: {true_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(PROCESSED_DIR / 'phish_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_phish, df_valid], ignore_index=True)\n",
    "statistics(df_combined)\n",
    "df_combined.drop(columns=['website_url'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = {\n",
    "    'website_url',          # NOT NEEDED\n",
    "    'sslfinal_state',       # BAD\n",
    "    'having_ip_address',    # USELESS\n",
    "    'port'                  # USELESS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta': {'request': {'domain': 'contec.com', 'limit': 10, 'format': 'json'}, 'status': 'Success', 'last_updated': '2024-10-31'}, 'similar_rank': {'rank': 219447}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "api_key = \"f7ee35680b6b481fa77a02156fe59bfd\"\n",
    "\n",
    "def get_digital_rank(domain):\n",
    "    try:\n",
    "        if domain.startswith(\"www.\"):\n",
    "            domain = domain[4:]\n",
    "            \n",
    "        url = f\"https://api.similarweb.com/v1/similar-rank/{domain}/rank?api_key={api_key}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return response.text\n",
    "    except Exception:\n",
    "        print(f\"An error occurred while fetching the digital rank for {domain} {str(Exception.__name__)}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "print(get_digital_rank(\"contec.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://brausuario.seuprogramabra.biz.ua/html/\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "url = \"https://brausuario.seuprogramabra.biz.ua/html/?cliente=bWlndWVsbWdsQHVvbC5jb20uYnI=&amp;key=29dea2cacd927a9c3b30e2f027fd0564&amp\"\n",
    "parsed_url = urlparse(url)\n",
    "full_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}\"\n",
    "print(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status_code': 200, 'response': [{'status_code': 200, 'error': '', 'page_rank_integer': 2, 'page_rank_decimal': 2.28, 'rank': '49033383', 'domain': 'help.contec.com'}], 'last_updated': '26th Oct 2024'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def get_open_page_rank(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        url = \"https://openpagerank.com/api/v1.0/getPageRank\"\n",
    "        params = {\n",
    "            \"domains[]\": domain\n",
    "        }\n",
    "\n",
    "        headers = {\n",
    "            \"API-OPR\": os.getenv('OPEN_PAGE_RANK_API_KEY')\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return None\n",
    "    except Exception:\n",
    "        return None\n",
    "    \n",
    "print(get_open_page_rank(\"https://help.contec.com/pc-helper/api-tool-wdm/en/mergedProjects/CAIO/sample_program/VC/Ao/AoGeneratingRingMemory.htm\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "781-project-_wk9diy5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
