{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import dns.resolver\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../data')\n",
    "PHISH_DIR = DATA_DIR / 'phishtank'\n",
    "LEGIT_DIR = DATA_DIR / 'common_crawl'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "PHISH_DATA = PHISH_DIR / 'collected_data.csv'\n",
    "LEGIT_DATA = LEGIT_DIR / 'collected_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish = pd.read_csv(PHISH_DATA)\n",
    "df_valid = pd.read_csv(LEGIT_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reapplying Rules\n",
    "Some address based indicators were updated after they were collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urljoin\n",
    "import whois\n",
    "import tldextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_whois(url):\n",
    "    \"\"\"Gets the WHOIS information of a URL.\"\"\"\n",
    "    try:\n",
    "        whois_data = whois.whois(url.lower())\n",
    "        return whois_data\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "# CloudFlare\n",
    "top_phishing_tlds = [\n",
    "    # Cheap and Open TLDs\n",
    "    \".xyz\", \".top\", \".club\", \".online\", \".shop\", \".site\", \".vip\", \".buzz\",\n",
    "\n",
    "    # Freenom TLDs (Free Domains)\n",
    "    \".tk\", \".ml\", \".ga\", \".cf\", \".gq\",\n",
    "\n",
    "    # Geographic and Niche TLDs less commonly used for legitimate purposes\n",
    "    \".ly\", \".to\", \".ru\", \".cn\", \".su\"\n",
    "]\n",
    "\n",
    "def is_statistical_report(url):\n",
    "    \"\"\"Determines if the URL has a suspicious statistical report based on phishing domains or IPs.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    \n",
    "    if ext.suffix in top_phishing_tlds:\n",
    "        return -1  # Phishing\n",
    "    \n",
    "    return 1 \n",
    "\n",
    "def core_domain(url):\n",
    "    \"\"\"Normalize the URL by extracting only the core domain using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    core_domain = f\"{extracted.domain}.{extracted.suffix}\"\n",
    "    return core_domain\n",
    "\n",
    "def domain_name(url):\n",
    "    \"\"\"Normalize the URL by extracting only the domain name using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    return extracted.domain\n",
    "\n",
    "url_shortening_services = [\n",
    "    # Legitimate Shortening Services\n",
    "    \"bit.ly\", \"tinyurl.com\", \"t.co\", \"is.gd\", \"ow.ly\",\n",
    "    \"buff.ly\", \"rebrand.ly\", \"sh.st\", \"adf.ly\", \"bl.ink\",\n",
    "    \"clck.ru\", \"mcaf.ee\", \"tiny.cc\", \"fb.me\", \"amzn.to\",\n",
    "    \"lnkd.in\", \"yt.be\", \"wp.me\", \"git.io\", \"nyti.ms\",\n",
    "    \"es.pn\", \"cnn.it\",\n",
    "\n",
    "    # Known Suspicious or Exploited Shorteners\n",
    "    \"goo.gl\", \"cut.ly\", \"rb.gy\", \"soo.gd\", \"t.ly\",\n",
    "    \"v.gd\", \"qr.ae\", \"x.co\", \"zl.gg\", \"tr.im\",\n",
    "    \"linktr.ee\", \"phurl.me\", \"short.cm\", \"cutt.ly\"\n",
    "]\n",
    "def is_shortening_service(url):\n",
    "    \"\"\"Determines if the URL uses a URL shortening service.\"\"\"\n",
    "    core = core_domain(url)\n",
    "    if core in url_shortening_services:\n",
    "        return -1\n",
    "    return 1\n",
    "\n",
    "def is_url_long(url):\n",
    "    \"\"\"Determines if the URL length is suspicious or phishing based on length.\"\"\"\n",
    "    url_length = len(url)\n",
    "    \n",
    "    if url_length < 54:\n",
    "        return 1  # Legitimate\n",
    "    elif 54 <= url_length <= 75:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1  # Phishing\n",
    "\n",
    "def is_double(url):\n",
    "    \"\"\"Determines if the URL redirects using '//'.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.scheme == \"http\":\n",
    "        limit_position = 6\n",
    "    elif parsed_url.scheme == \"https\":\n",
    "        limit_position = 7\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    last_occurrence_index = url.rfind(\"//\")\n",
    "\n",
    "    if last_occurrence_index > limit_position:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def is_dns_record(url, timeout=5):\n",
    "    \"\"\"Check if the domain or subdomain has DNS records.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "    \n",
    "    resolver = dns.resolver.Resolver()\n",
    "    resolver.timeout = timeout\n",
    "    resolver.lifetime = timeout  # Set a timeout for the entire resolution process\n",
    "    \n",
    "    try:\n",
    "        a_records = resolver.resolve(domain, 'A')\n",
    "        if a_records:\n",
    "            return 1\n",
    "    except dns.resolver.NoAnswer:\n",
    "        pass\n",
    "    except dns.resolver.NXDOMAIN:\n",
    "        return -1\n",
    "    except dns.exception.Timeout:\n",
    "        return -1\n",
    "    except dns.resolver.NoNameservers:\n",
    "        return -1\n",
    "    \n",
    "    try:\n",
    "        aaaa_records = resolver.resolve(domain, 'AAAA')\n",
    "        if aaaa_records:\n",
    "            return 1\n",
    "    except dns.resolver.NoAnswer:\n",
    "        pass\n",
    "    except dns.resolver.NXDOMAIN:\n",
    "        return -1\n",
    "    except dns.exception.Timeout:\n",
    "        return -1\n",
    "    except dns.resolver.NoNameservers:\n",
    "        return -1\n",
    "    \n",
    "    return -1\n",
    "    \n",
    "def is_having_sub_domain(url):\n",
    "    \"\"\"Classifies a URL based on the number of subdomains.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    subdomain = ext.subdomain\n",
    "    num_subdomains = len(subdomain.split('.')) if subdomain else 0\n",
    "    \n",
    "    if num_subdomains == 0:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 1:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 2:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def is_abnormal_url(url):\n",
    "    \"\"\"Determines if the URL is abnormal.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    host_name = ext.domain + '.' + ext.suffix\n",
    "    w = whois.whois(url)\n",
    "    if w and 'domain_name' in w:\n",
    "        domain_names = w['domain_name']\n",
    "        print(f\"Domain names: {domain_names}\")\n",
    "        if isinstance(domain_names, list):\n",
    "            for domain in domain_names:\n",
    "                if host_name.lower() == domain.lower():\n",
    "                    return 1\n",
    "        elif isinstance(domain_names, str):\n",
    "            if host_name.lower() == domain_names.lower():\n",
    "                return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url_online(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        # Check if the status code indicates success (2xx range)\n",
    "        if response.status_code >= 200 and response.status_code < 300:\n",
    "            return True  # URL is online\n",
    "        else:\n",
    "            print (f\"URL is not online, or is responding with an error code: {response.status_code}\")\n",
    "            return False  # URL is not online, or is responding with an error code\n",
    "    except requests.RequestException:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()  # This enables tqdm for pandas' apply method\n",
    "\n",
    "# Apply the function with progress tracking\n",
    "df_phish = df_phish[df_phish['website_url'].progress_apply(is_url_online)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of phishing URLs after filtering: {len(df_phish)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish.drop_duplicates(subset=['website_url'], inplace=True)\n",
    "df_valid.drop_duplicates(subset=['website_url'], inplace=True)\n",
    "\n",
    "df_phish['statistical_report'] = df_phish['website_url'].apply(is_statistical_report)\n",
    "df_valid['statistical_report'] = df_valid['website_url'].apply(is_statistical_report)\n",
    "df_phish['shortining_service'] = df_phish['website_url'].apply(is_shortening_service)\n",
    "df_valid['shortining_service'] = df_valid['website_url'].apply(is_shortening_service)\n",
    "df_phish['url_length'] = df_phish['website_url'].apply(is_url_long)\n",
    "df_valid['url_length'] = df_valid['website_url'].apply(is_url_long)\n",
    "df_phish['having_sub_domain'] = df_phish['website_url'].apply(is_having_sub_domain)\n",
    "df_valid['having_sub_domain'] = df_valid['website_url'].apply(is_having_sub_domain)\n",
    "df_phish['double_slash_redirecting'] = df_phish['website_url'].apply(is_double)\n",
    "df_valid['double_slash_redirecting'] = df_valid['website_url'].apply(is_double)\n",
    "df_phish['dnsrecord'] = df_phish['website_url'].progress_apply(is_dns_record)\n",
    "df_valid['dnsrecord'] = df_valid['website_url'].progress_apply(is_dns_record)\n",
    "df_phish['abnormal_url'] = df_phish['website_url'].progress_apply(is_abnormal_url)\n",
    "df_valid['abnormal_url'] = df_valid['website_url'].progress_apply(is_abnormal_url)\n",
    "df_phish['result'] = -1\n",
    "df_valid['result'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_phish.to_csv(PROCESSED_DIR / 'phish_data.csv', index=False)\n",
    "df_valid.to_csv(PROCESSED_DIR / 'valid_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "def create_table(data, headers):\n",
    "    print(tabulate(data, headers=headers, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(df):\n",
    "    metrics = []\n",
    "    data = []\n",
    "    for col in df.columns:\n",
    "        if col == 'result':\n",
    "            continue\n",
    "        \n",
    "        value_counts = df[col].value_counts().reindex([-1, 0, 1], fill_value=0)\n",
    "        phishing = value_counts.get(-1, 0)\n",
    "        suspicious = value_counts.get(0, 0)\n",
    "        legitimate = value_counts.get(1, 0)\n",
    "        \n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        df['result'] = pd.to_numeric(df['result'], errors='coerce')\n",
    "        \n",
    "        TP = ((df[col] == -1) & (df['result'] == -1)).sum()\n",
    "        FP = (((df[col] == -1) | (df[col] == 0)) & (df['result'] == 1)).sum()\n",
    "        TN = ((df[col] == 1) & (df['result'] == 1)).sum()\n",
    "        FN = (((df[col] == 1) | (df[col] == 0)) & (df['result'] == -1)).sum()\n",
    "        \n",
    "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        accuracy = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "        metrics.append({\n",
    "            'Feature': col,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'Accuracy': accuracy\n",
    "        })\n",
    "        data.append([col, phishing, suspicious, legitimate, precision, recall, accuracy])\n",
    "\n",
    "\n",
    "    headers = [\"Feature\",\"Phishing (-1)\", \"Suspicious (0)\",\"Legitimate (1)\", \"Precision (%)\", \"Recall (%)\", \"Accuracy (%)\"]\n",
    "    create_table(data, headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(df_phish)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_phish, df_valid], ignore_index=True)\n",
    "statistics(df_combined)\n",
    "df_combined.drop(columns=['website_url'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_features = {\n",
    "    'website_url',          # NOT NEEDED\n",
    "    'sslfinal_state',       # BAD\n",
    "    'having_ip_address',    # USELESS\n",
    "    'port'                  # USELESS\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "781-project-_wk9diy5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
