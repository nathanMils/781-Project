{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDICATORS\n",
    "- a list of all there inidcators and there implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import whois\n",
    "import ssl\n",
    "import socket\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import tldextract\n",
    "import logging\n",
    "import time\n",
    "import dns.resolver\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import coloredlogs\n",
    "\n",
    "load_dotenv(dotenv_path='./.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    coloredlogs.install(level='INFO', fmt=log_format)\n",
    "\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample DATA for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = 'path_to_your_csv_file.csv'\n",
    "df_csv = pd.read_csv(csv_file_path)\n",
    "\n",
    "json_file_path = 'path_to_your_json_file.json'\n",
    "with open(json_file_path, 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "df_json = pd.DataFrame(json_data)\n",
    "\n",
    "merged_df = pd.merge(df_csv, df_json, on='id', how='inner', validate='one_to_one')\n",
    "\n",
    "html_features = merged_df['html'].tolist()\n",
    "\n",
    "print(merged_df)\n",
    "print(html_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "## 1: Legitimate\n",
    "## 0: Suspicious\n",
    "## -1: Phishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_domain(url):\n",
    "    \"\"\"Normalize the URL by extracting only the core domain using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    core_domain = f\"{extracted.domain}.{extracted.suffix}\"\n",
    "    return core_domain\n",
    "\n",
    "def domain_name(url):\n",
    "    \"\"\"Normalize the URL by extracting only the domain name using tldextract.\"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    return extracted.domain\n",
    "\n",
    "def lower_case(url):\n",
    "    \"\"\"Normalize the URL by converting it to lowercase.\"\"\"\n",
    "    return url.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAS IP ADDRESS\n",
    "#### Value: Essentially useless\n",
    "Almost no instances of phishing urls utilizing IP addresses anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Using the IP Address\n",
    "## STATUS: FINISHED\n",
    "def is_having_ip(url):\n",
    "    \"\"\"Determines if the URL has an IP address.\"\"\"\n",
    "    try:\n",
    "        hostname = urlparse(url).hostname\n",
    "        if hostname is None:\n",
    "            return False\n",
    "        \n",
    "        ipv4_pattern = re.compile(r'^(?:\\d{1,3}\\.){3}\\d{1,3}$')\n",
    "        hex_pattern = re.compile(r'^(?:0x[0-9A-Fa-f]{1,2}\\.){3}0x[0-9A-Fa-f]{1,2}$')\n",
    "        \n",
    "        if ipv4_pattern.match(hostname) or hex_pattern.match(hostname):\n",
    "            return -1\n",
    "        return 1\n",
    "    except Exception:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL LONG\n",
    "#### Value: OK\n",
    "While many phishing urls do have much longer urls, the same can be said for legitamate websites (google searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Long URL to Hide the Suspicious Part\n",
    "## STATUS: FINISHED\n",
    "def is_url_long(url):\n",
    "    \"\"\"Determines if the URL length is suspicious or phishing based on length.\"\"\"\n",
    "    url_length = len(url)\n",
    "    \n",
    "    if url_length < 54:\n",
    "        return 1  # Legitimate\n",
    "    elif 54 <= url_length <= 75:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1  # Phishing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHORTENING SERVICES\n",
    "#### Value: Good\n",
    "Many phishing websites utilize shortening services to hide.\n",
    "However, this is not a clear indicator. But it does indicate the need to look at other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Using URL Shortening Services \"TinyURL\"\n",
    "## STATUS: FINISHED\n",
    "## List of URL shortening services\n",
    "url_shortening_services = [\n",
    "    \"tinyurl.com\", \"bit.ly\", \"t.co\", \"goo.gl\", \"is.gd\", \"buff.ly\",\n",
    "    \"adf.ly\", \"ow.ly\", \"bit.do\", \"cutt.ly\", \"shorte.st\", \"clck.ru\",\n",
    "    \"tiny.cc\", \"tr.im\", \"x.co\", \"soo.gd\", \"s2r.co\", \"bl.ink\", \"mcaf.ee\",\n",
    "    \"urlz.fr\", \"shorturl.at\"\n",
    "]\n",
    "def is_shortening_service(url):\n",
    "    \"\"\"Determines if the URL uses a URL shortening service.\"\"\"\n",
    "    core = core_domain(url)\n",
    "    if core in url_shortening_services:\n",
    "        return -1\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAVING @ SYMBOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: URL's having \"@\" Symbol\n",
    "## STATUS: FINISHED\n",
    "def is_having_at_symbol(url):\n",
    "    \"\"\"Determines if the URL contains an '@' symbol.\"\"\"\n",
    "    if '@' in url:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOUBLE SLASH\n",
    "- account for both http and https\n",
    "#### Value: OK\n",
    "Simply not very common anymore, sometimes are blocked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Redirecting using \"//\"\n",
    "## STATUS: FINISHED\n",
    "def is_double(url):\n",
    "    \"\"\"Determines if the URL redirects using '//'.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    if parsed_url.scheme == \"http\":\n",
    "        limit_position = 6\n",
    "    elif parsed_url.scheme == \"https\":\n",
    "        limit_position = 7\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    last_occurrence_index = url.rfind(\"//\")\n",
    "\n",
    "    if last_occurrence_index > limit_position:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Prefix Suffix\n",
    "#### Value: Good\n",
    "Many phishing URLs use - to obfuscate domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Adding Prefix or Suffix Separated by (-) to the Domain\n",
    "## STATUS: FINISHED\n",
    "def is_prefix_suffix(url):\n",
    "    \"\"\"Determines if the URL has a prefix or suffix separated by a hyphen.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    domain_name = parsed_url.netloc\n",
    "\n",
    "    if '-' in domain_name:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple SUBDOMAINS\n",
    "#### Value: Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Sub Domain and Multi Sub Domains\n",
    "## STATUS: FINISHED\n",
    "def is_having_sub_domain(url):\n",
    "    \"\"\"Classifies a URL based on the number of subdomains.\"\"\"\n",
    "    ext = tldextract.extract(url)\n",
    "    subdomain = ext.subdomain\n",
    "    num_subdomains = len(subdomain.split('.')) if subdomain else 0\n",
    "    \n",
    "    if num_subdomains == 0:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 1:\n",
    "        return 1  # Legitimate\n",
    "    elif num_subdomains == 2:\n",
    "        return 0  # Suspicious\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSL Trusted\n",
    "#### Value: BAD - OUTDATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: HTTPS (Hyper Text Transfer Protocol with Secure Sockets Layer)\n",
    "## STATUS: FINISHED\n",
    "## List of trusted Certificate Authorities\n",
    "TRUSTED_ISSUER_KEYWORDS = {\n",
    "    \"GeoTrust\", \"GoDaddy\", \"Network Solutions\", \"Thawte\",\n",
    "    \"Comodo\", \"Doster\", \"VeriSign\", \"DigiCert\", \"WR2\",\n",
    "    \"GlobalSign\", \"Entrust\", \"Symantec\", \"Let's Encrypt\",\n",
    "    \"Amazon\", \"Trustwave\", \"QuoVadis\",\n",
    "    \"SwissSign\", \"Sectigo\", \"WoSign\", \"CNNIC\",\n",
    "    \"StartCom\", \"GeoTrust\", \"Verisign\"\n",
    "}\n",
    "\n",
    "\n",
    "def is_trusted_issuer(issuer_common_name):\n",
    "    return any(keyword in issuer_common_name for keyword in TRUSTED_ISSUER_KEYWORDS)\n",
    "def is_https(url):\n",
    "    \"\"\"Determines if the URL uses HTTPS.\"\"\"\n",
    "    try:\n",
    "        hostname = url.replace(\"https://\", \"\").replace(\"http://\", \"\").split('/')[0]\n",
    "\n",
    "        context = ssl.create_default_context()\n",
    "        with socket.create_connection((hostname, 443)) as sock:\n",
    "            with context.wrap_socket(sock, server_hostname=hostname) as ssock:\n",
    "                cert = ssock.getpeercert()\n",
    "\n",
    "        issuer = dict(x[0] for x in cert['issuer'])\n",
    "        issuer_common_name = issuer.get('commonName', '')\n",
    "\n",
    "\n",
    "        if not cert:\n",
    "            return 1\n",
    "        \n",
    "\n",
    "        if not is_trusted_issuer(issuer_common_name):\n",
    "            return 0\n",
    "\n",
    "\n",
    "        valid_from = datetime.strptime(cert['notBefore'], '%b %d %H:%M:%S %Y %Z')\n",
    "\n",
    "\n",
    "        age_in_years = (datetime.now() - valid_from).days / 365.25\n",
    "        if age_in_years >= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    except Exception:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Registration Length\n",
    "#### Value: Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Domain Registration Length\n",
    "## STATUS: FINISHED\n",
    "def is_domain_registration_length(url):\n",
    "    \"\"\"Determines if the URL's domain registration length is suspicious.\"\"\"\n",
    "    try:\n",
    "        domain = whois.whois(url)\n",
    "        creation_date = domain.creation_date\n",
    "        expiration_date = domain.expiration_date\n",
    "\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        if isinstance(expiration_date, list):\n",
    "            expiration_date = expiration_date[0]\n",
    "\n",
    "        if creation_date and expiration_date:\n",
    "            registration_length = (expiration_date - creation_date).days / 365\n",
    "            if registration_length < 1:\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except Exception:\n",
    "        logging.error(\"Error in domain registration length\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Registration LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Domain Registration Length\n",
    "## STATUS: FINISHED\n",
    "def is_domain_registration_length(url):\n",
    "    \"\"\"Determines if the URL's domain registration length is suspicious.\"\"\"\n",
    "    try:\n",
    "        domain = whois.whois(url)\n",
    "        creation_date = domain.creation_date\n",
    "        expiration_date = domain.expiration_date\n",
    "\n",
    "        if isinstance(creation_date, list):\n",
    "            creation_date = creation_date[0]\n",
    "        if isinstance(expiration_date, list):\n",
    "            expiration_date = expiration_date[0]\n",
    "\n",
    "        if creation_date and expiration_date:\n",
    "            registration_length = (expiration_date - creation_date).days / 365\n",
    "            if registration_length < 1:\n",
    "                return -1\n",
    "            else:\n",
    "                return 1\n",
    "        else:\n",
    "            return -1\n",
    "    except Exception:\n",
    "        logging.error(\"Error in domain registration length\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Favicon\n",
    "#### Value: OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE\n",
    "## STATUS: FINISHED\n",
    "def is_favicon(url, soup):\n",
    "    \"\"\"Determines if the URL has a favicon.\"\"\"\n",
    "    \n",
    "    main_domain = urlparse(url).netloc\n",
    "    \n",
    "    favicon_link = soup.find(\"link\", rel=lambda value: value and 'icon' in value.lower())\n",
    "    \n",
    "    if not favicon_link or not favicon_link.get(\"href\"):\n",
    "        return 1\n",
    "    \n",
    "    favicon_url = urljoin(url, favicon_link.get(\"href\"))\n",
    "    favicon_domain = urlparse(favicon_url).netloc\n",
    "    \n",
    "    if favicon_domain == main_domain:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PORT\n",
    "#### Value: Essentially useless\n",
    "No occurance of altenrate port numbers used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: Using Non-Standard Port\n",
    "## STATUS: FINISHED\n",
    "## List of preferred ports\n",
    "preferred_ports = [80, 443]\n",
    "## List of non-preferred ports\n",
    "non_preferred_ports = [21, 22, 23, 445, 1433, 1521, 3306, 3389]\n",
    "def is_port(url):\n",
    "    \"\"\"Determines if the URL uses a non-standard port.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    port = parsed_url.port\n",
    "    \n",
    "    if port is None:\n",
    "        if parsed_url.scheme == 'http':\n",
    "            port = 80\n",
    "        elif parsed_url.scheme == 'https':\n",
    "            port = 443\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    if port in preferred_ports:\n",
    "        return 1\n",
    "    \n",
    "    elif port in non_preferred_ports:\n",
    "        return -1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTTPS Token\n",
    "#### Value: OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## RULE: HTTP and HTTPS Tokens\n",
    "## STATUS: FINISHED\n",
    "def is_https_token(url):\n",
    "    \"\"\"Determines if the URL has 'https' tokens.\"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    domain = parsed_url.netloc\n",
    "    \n",
    "    # Check if the \"https\" token appears in the domain part\n",
    "    if \"https\" in domain:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW FEATURES\n",
    "- Detection of numbers in domain (0,1)\n",
    "- Special Characters (0,1)\n",
    "- Homoglyhs (1,0,-1)\n",
    "\n",
    "## Brand Impersonation Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idna\n",
    "\n",
    "# 1. Presence of Numbers in the Domain\n",
    "def has_numbers_in_domain(url: str) -> bool:\n",
    "    domain = urlparse(url).netloc\n",
    "    if bool(re.search(r'\\d', domain)):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# 2. Presence of Special Characters in the Domain\n",
    "def has_special_characters_in_domain(url: str) -> bool:\n",
    "    domain = urlparse(url).netloc\n",
    "    special_chars = set(\"!#$%&'()*+,/:;<=>?@[\\\\]^`{|}~\")\n",
    "    if any(char in special_chars for char in domain):\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "# 3. Presence of IDN Spoofing in the Domain\n",
    "HOMOGLYPHS = {\n",
    "    'a': ['α', 'а'],  # Latin 'a' vs Greek 'alpha' and Cyrillic 'a'\n",
    "    'o': ['ο', 'օ'],  # Latin 'o' vs Greek 'omicron' and Armenian 'o'\n",
    "    'e': ['е'],       # Latin 'e' vs Cyrillic 'e'\n",
    "    'i': ['і', '١'],   # Latin 'i' vs Cyrillic 'і' and Arabic digit '1'\n",
    "    'l': ['ӏ', '١'],   # Latin 'l' vs Cyrillic 'ӏ' and Arabic digit '1'\n",
    "    'u': ['υ'],       # Latin 'u' vs Greek 'upsilon'\n",
    "    'c': ['с'],       # Latin 'c' vs Cyrillic 'с'\n",
    "    'n': ['п'],       # Latin 'n' vs Cyrillic 'п'\n",
    "}\n",
    "\n",
    "## NOT USED NOT ENOUGH DATA TO BE AFFECTIVE\n",
    "def homoglyph(url):\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        domain = parsed_url.netloc\n",
    "        \n",
    "        is_idn = not domain.isascii()\n",
    "        suspicious_chars = []\n",
    "\n",
    "        if is_idn:\n",
    "            for char in domain:\n",
    "                for key, glyphs in HOMOGLYPHS.items():\n",
    "                    if char in glyphs:\n",
    "                        suspicious_chars.append((char, key))\n",
    "            \n",
    "            if suspicious_chars:\n",
    "                return -1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 1\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing URL: {e}\")\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "KNOWN_BRANDS_DOMAINS = [\n",
    "    \"microsoft\",\n",
    "    \"apple\",\n",
    "    \"google\",\n",
    "    \"facebook\",\n",
    "    \"whatsapp\",\n",
    "    \"amazon\",\n",
    "    \"alibaba\",\n",
    "    \"adobe\",\n",
    "    \"twitter\",\n",
    "    \"adidas\",\n",
    "    \"netflix\",\n",
    "    \"paypal\",\n",
    "    \"bankofamerica\",\n",
    "    \"chase\",\n",
    "    \"wellsfargo\",\n",
    "    \"linkedin\",\n",
    "    \"ebay\",\n",
    "    \"instagram\",\n",
    "    \"zoom\",\n",
    "    \"dropbox\",\n",
    "    \"youtube\",\n",
    "    \"airbnb\",\n",
    "    \"spotify\",\n",
    "    \"appleid\"\n",
    "]\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "def extract_domain_and_subdomains(url):\n",
    "    \"\"\"\n",
    "    Extract the domain, subdomains, and TLD from a given URL using tldextract.\n",
    "    \"\"\"\n",
    "    extracted = tldextract.extract(url)\n",
    "    subdomains = extracted.subdomain.split('.') if extracted.subdomain else []\n",
    "    domain = extracted.domain\n",
    "    return domain, subdomains\n",
    "\n",
    "def overlapping_substrings(string, n):\n",
    "    \"\"\"\n",
    "    Breaks the string into overlapping substrings of length n with a stride of 1.\n",
    "    If there are fewer than n characters remaining at the end, it takes the remaining characters.\n",
    "    \"\"\"\n",
    "    substrings = []\n",
    "    for i in range(len(string) - n + 1):\n",
    "        substrings.append(string[i:i + n])\n",
    "    \n",
    "    if len(string) - (len(string) - n + 1) > 0:\n",
    "        substrings.append(string[-n:])\n",
    "    \n",
    "    return substrings\n",
    "\n",
    "def check_brands(url, brand_name=\"microsoft\"):\n",
    "    \"\"\"\n",
    "    Analyzes the URL for phishing indicators based on domain and subdomain similarity to brand name.\n",
    "    Uses Levenshtein distance normalized by the length of the target brand name.\n",
    "    \"\"\"\n",
    "    domain, subdomains = extract_domain_and_subdomains(url)\n",
    "    domain_and_subdomains = ''.join(sub.replace('.', '') for sub in subdomains) + domain.replace('.', '')\n",
    "    brand_len = len(brand_name)\n",
    "    domain_substrings = overlapping_substrings(domain_and_subdomains, brand_len)\n",
    "    domain_levenshtein_distances = [Levenshtein.distance(sub, brand_name) for sub in domain_substrings]\n",
    "    \n",
    "    min_distance = min(domain_levenshtein_distances)\n",
    "    normalized_distance = min_distance / brand_len\n",
    "    return normalized_distance\n",
    "\n",
    "def is_brand_impersonation_lev(url):\n",
    "    \"\"\"\n",
    "    Determines if the URL is impersonating a known brand.\n",
    "    \"\"\"\n",
    "    current = 1\n",
    "    for brand in KNOWN_BRANDS_DOMAINS:\n",
    "        distance = check_brands(url, brand)\n",
    "        if distance < 0.2:\n",
    "            return -1\n",
    "        elif distance < 0.5:\n",
    "            current = 0\n",
    "    return current\n",
    "\n",
    "url = \"http://demo-apple.serveirc.com/\"\n",
    "url = url.replace(\"-\", \"\")\n",
    "result = is_brand_impersonation_lev(url)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import tldextract\n",
    "\n",
    "KNOWN_BRANDS_DOMAINS = [\n",
    "    \"microsoft\",\n",
    "    \"apple\",\n",
    "    \"google\",\n",
    "    \"facebook\",\n",
    "    \"whatsapp\",\n",
    "    \"amazon\",\n",
    "    \"alibaba\",\n",
    "    \"adobe\",\n",
    "    \"twitter\",\n",
    "    \"adidas\",\n",
    "    \"netflix\",\n",
    "    \"paypal\",\n",
    "    \"bankofamerica\",\n",
    "    \"chase\",\n",
    "    \"wellsfargo\",\n",
    "    \"linkedin\",\n",
    "    \"ebay\",\n",
    "    \"instagram\",\n",
    "    \"zoom\",\n",
    "    \"dropbox\",\n",
    "    \"youtube\",\n",
    "    \"airbnb\",\n",
    "    \"spotify\",\n",
    "    \"appleid\"\n",
    "]\n",
    "        \n",
    "def is_brand_impersonation_fuzzy(url):\n",
    "    \"\"\"\n",
    "    Analyzes the URL for phishing indicators based on domain and subdomain similarity to brand name.\n",
    "    Uses fuzzy matching (Levenshtein distance) to compare strings.\n",
    "    \"\"\"\n",
    "    domain, subdomains = extract_domain_and_subdomains(url)\n",
    "    current = 1\n",
    "    brand_similarities = {}\n",
    "    for brand in KNOWN_BRANDS_DOMAINS:\n",
    "        similarity = fuzz.ratio(domain, brand)\n",
    "        if similarity > 70:\n",
    "            return -1\n",
    "        elif similarity > 50:\n",
    "            current = 0\n",
    "    \n",
    "    for brand in KNOWN_BRANDS_DOMAINS:\n",
    "        for subdomain in subdomains:\n",
    "            similarity = fuzz.ratio(subdomain, brand)\n",
    "            if similarity > 70:\n",
    "                return -1\n",
    "            elif similarity > 50:\n",
    "                current = 0\n",
    "    return current\n",
    "\n",
    "# Example usage\n",
    "url = \"http://demo-apple.serveirc.com/\"  # Example of a phishing domain\n",
    "url = url.replace('-', '')\n",
    "result = is_brand_impersonation_fuzzy(url)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Result: -1, Execution Time: 0.00030440000409726053 seconds\n",
      "Lev Result: -1, Execution Time: 0.00013220000255387276 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def measure_execution_time(func, *args, **kwargs):\n",
    "    start_time = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.perf_counter()\n",
    "    execution_time = end_time - start_time\n",
    "    return result, execution_time\n",
    "\n",
    "url = \"http://demo-apple.serveirc.com/\"\n",
    "url = url.replace(\"-\", \"\")\n",
    "result, exec_time = measure_execution_time(is_brand_impersonation_fuzzy, url)\n",
    "print(f\"Fuzzy Result: {result}, Execution Time: {exec_time} seconds\")\n",
    "result, exec_time = measure_execution_time(is_brand_impersonation_lev, url)\n",
    "print(f\"Lev Result: {result}, Execution Time: {exec_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "781-project-_wk9diy5-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
